{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "htfa_tutorial.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvUCqwpvlqMj"
      },
      "source": [
        "# ☞ Background and overview #\n",
        "\n",
        "We'll be learning how to create movies of dynamic brain networks using single-subject and multi-subject fMRI data.  After getting the dataset and wrangling it into the proper format, there are three basic steps:\n",
        "1. Use (Hierarchical) Topographic Factor Analysis [(H)TFA] to obtain a set of network \"hubs,\" and the moment-by-moment hub activations.  Model details may be found [here](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094914) and [here](http://www.biorxiv.org/content/early/2017/02/07/106690).  This creates a simplified version of the full-brain data that is especially useful for computing dynamic network patterns.\n",
        "1. Use the hub activations to approximate the average functional connectivity matrix, and to compute the dynamic connectivity patterns reflected by the data.  To estimate functional connectivity patterns in multi-subject data, we'll be using Inter-Subject Functional Connectivity (ISFC), which you can read more about [here](https://docs.wixstatic.com/ugd/b75639_92eab30b43284ca0bd163e3daa709eda.pdf).\n",
        "1. Use [nilearn](http://nilearn.github.io/) and [hypertools](http://hypertools.readthedocs.io/en/latest/) to visualize the results and create pretty animations.\n",
        "\n",
        "## Quick start guide\n",
        "- One way to go through this tutorial is to start at the top and go through section by section (executing each cell in turn).\n",
        "- Alternatively, you can skim through the entire notebook and just run or explore the parts you're interested in.\n",
        "    - Some sections below are marked with a ☞.  The blocks of code following those sections are required to run the main analyses.  Those marked sections are also the ones that contain code you'll need if you want to run larger scale analyses, e.g. outside of this tutorial.\n",
        "    - Other sections are marked with a ⭑.  These contain suggested \"challenge problems\" that you can solve to gain further fluency with these approaches.\n",
        "- A third option is to run all of the code in sequence (Cell > Run All) before starting to read it through.  That will generate all of the figures and give you access to the data and relevant variables, and then you can go back and explore the parts that look interesting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtDOPSMwpOQc"
      },
      "source": [
        "!pip install nilearn\n",
        "!pip install brainiak\n",
        "!pip install hypertools\n",
        "!pip uninstall scikit-learn==1.0.1 -y\n",
        "!pip install scikit-learn>0.24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXGUpFzMuAD7"
      },
      "source": [
        "#!pip uninstall brainiak -y\n",
        "!pip --version\n",
        "!pip install -U setuptools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8FWs8zderE",
        "outputId": "d2a60713-3784-4166-d39b-b600a4ebccec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install older version of brainiak\n",
        "#!wget https://github.com/brainiak/brainiak/archive/refs/tags/v0.6.tar.gz\n",
        "#!mkdir brainiak_src\n",
        "#!tar xvf v0.6.tar.gz --directory brainiak_src\n",
        "!python -m pip install --no-use-pep517 -e ./brainiak_src/brainiak-0.6 #https://github.com/brainiak/brainiak/archive/refs/tags/v0.8.zip "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/brainiak_src/brainiak-0.6\n",
            "\u001b[33mWARNING: Discarding file:///content/brainiak_src/brainiak-0.6. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjDWUnFNlqMq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "0b922d88-2e8b-4ba8-ba98-f6e4b04c7568"
      },
      "source": [
        "from brainiak.factoranalysis.tfa import TFA\n",
        "from brainiak.factoranalysis.htfa import HTFA\n",
        "\n",
        "import hypertools as hyp\n",
        "import seaborn as sns\n",
        "import nilearn.plotting as niplot\n",
        "import matplotlib as mpl\n",
        "\n",
        "from nilearn.input_data import NiftiMasker\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import scipy.spatial.distance as sd\n",
        "\n",
        "import zipfile\n",
        "import os, sys, glob, warnings\n",
        "from copy import copy as copy\n",
        "from mpi4py import MPI\n",
        "import urllib.request\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from IPython.display import YouTubeVideo, HTML\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fe728d3587c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbrainiak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactoranalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrainiak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactoranalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtfa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTFA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhypertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'brainiak'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV0hjnzWfnsj",
        "outputId": "f3e945f1-890a-497c-d24f-16cbe12ba6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import brainiak\n",
        "print(brainiak)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'brainiak' from '/usr/local/lib/python3.7/dist-packages/brainiak/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuqSdMZclqMt"
      },
      "source": [
        "## Experiment ##\n",
        "We'll be exploring a part of a dataset collected by Uri Hasson's lab.  The experiment had 36 participants listen *Pie Man*, a story told by Jim O'Grady as part of *The Moth* live storytelling event.  You can listen to the story here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NFC7FxXlqMt"
      },
      "source": [
        "YouTubeVideo('3nZzSUDECLo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTriGpB1lqMv"
      },
      "source": [
        "## Data ##\n",
        "The dataset comprises 36 preprocessed .nii files, and may be downloaded [here](http://dataspace.princeton.edu/jspui/handle/88435/dsp015d86p269k).  However, in the interest of running the analyses quickly, for this tutorial we're going to be working with data from just 3 participants (this smaller dataset may be found [here](http://discovery.dartmouth.edu/~jmanning/MIND/pieman_mini/pieman_data2.zip), and will be downloaded in the next cell).\n",
        "\n",
        "## Other datasets to explore ##\n",
        "[This repository](http://dataspace.princeton.edu/jspui/handle/88435/dsp0147429c369) has a bunch of interesting fMRI datasets in the same format as the sample dataset we'll explore below.\n",
        "\n",
        "[This dataset](https://github.com/HaxbyLab/raiders_data) collected by Jim Haxby's lab comprises fMRI data as people watched *Indiana Jones: Raiders of the Lost Ark*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SYyCqnmlqMv"
      },
      "source": [
        "#Download the data (takes a few minutes...)\n",
        "\n",
        "#change these lines if you want to download a different dataset!\n",
        "source = 'https://dataspace.princeton.edu/bitstream/88435/dsp015d86p269k/4/pieman_archive.tar.gz'\n",
        "destination = '/pieman_archive/pieman_archive.tar.gz'\n",
        "data_format = '.tar.gz' #file extension\n",
        "\n",
        "urllib.request.urlretrieve(source, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1ujtySihlqMw"
      },
      "source": [
        "#Unzip the data\n",
        "#zipfile.ZipFile(destination, 'r').extractall()\n",
        "#!mkdir -p pieman_archive/\n",
        "#!tar xvf pieman_archive.tar.gz --directory pieman_archive\n",
        "! mv ./pieman_archive/new_pieman/sub*/func/*.nii ./pieman_archive/\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fexsLWsyXn9Q",
        "outputId": "d2417f2e-08fd-4e0e-8255-265026453a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#niifiles = glob.glob(os.path.join(destination[0:-(len(data_format)+1)], '*.nii.gz'))\n",
        "#niifiles.extend(glob.glob(os.path.join(destination[0:-(len(data_format)+1)], '*.nii')))\n",
        "niifiles = os.listdir(\"pieman_archive\")\n",
        "niifiles = [\"pieman_archive/\"+f for f in niifiles if \".nii\" in f]\n",
        "niifiles"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pieman_archive/sub-75-task-rest1.nii',\n",
              " 'pieman_archive/sub-7-task-intact1.nii',\n",
              " 'pieman_archive/sub-11-task-word.nii',\n",
              " 'pieman_archive/sub-66-task-paragraph.nii',\n",
              " 'pieman_archive/sub-90-task-rest2.nii',\n",
              " 'pieman_archive/sub-30-task-intact2.nii',\n",
              " 'pieman_archive/sub-30-task-word.nii']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8OLe4GVXIfM"
      },
      "source": [
        "!rm -rf /pieman_archive/new_pieman/sub-64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lst_2rnClqMy"
      },
      "source": [
        "### ☞ Data formatting: .nii --> matrix format ###\n",
        "To computing HTFA-derived brain networks, we're going to first convert the .nii files into [CMU format](http://www.cs.cmu.edu/afs/cs/project/theo-73/www/science2008/README-data-documentation.txt), inspired by Tom Mitchell's website for his 2008 Science paper on predicting brain responses to common nouns ([link](http://www.cs.cmu.edu/afs/cs/project/theo-73/www/science2008/data.html)).\n",
        "\n",
        "We'll create a dictionary for each .nii (or .nii.gz) file with two elements:\n",
        "- `Y`: a number-of-timepoints by number-of-voxels matrix of voxel activations\n",
        "- `R`: a number-of-voxels by 3 matrix of voxel locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fsbvTHhnlqMz"
      },
      "source": [
        "def nii2cmu(nifti_file, mask_file=None):\n",
        "    def fullfact(dims):\n",
        "        '''\n",
        "        Replicates MATLAB's fullfact function (behaves the same way)\n",
        "        '''\n",
        "        vals = np.asmatrix(range(1, dims[0] + 1)).T\n",
        "        if len(dims) == 1:\n",
        "            return vals\n",
        "        else:\n",
        "            aftervals = np.asmatrix(fullfact(dims[1:]))\n",
        "            inds = np.asmatrix(np.zeros((np.prod(dims), len(dims))))\n",
        "            row = 0\n",
        "            for i in range(aftervals.shape[0]):\n",
        "                inds[row:(row + len(vals)), 0] = vals\n",
        "                inds[row:(row + len(vals)), 1:] = np.tile(aftervals[i, :], (len(vals), 1))\n",
        "                row += len(vals)\n",
        "            return inds\n",
        "    \n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        \n",
        "        img = nib.load(nifti_file)\n",
        "        mask = NiftiMasker(mask_strategy='background')\n",
        "        if mask_file is None:\n",
        "            mask.fit(nifti_file)\n",
        "        else:\n",
        "            mask.fit(mask_file)\n",
        "    \n",
        "    hdr = img.header\n",
        "    S = img.get_sform()\n",
        "    vox_size = hdr.get_zooms()\n",
        "    im_size = img.shape\n",
        "    \n",
        "    if len(img.shape) > 3:\n",
        "        N = img.shape[3]\n",
        "    else:\n",
        "        N = 1\n",
        "    \n",
        "    Y = np.float64(mask.transform(nifti_file)).copy()\n",
        "    vmask = np.nonzero(np.array(np.reshape(mask.mask_img_.dataobj, (1, np.prod(mask.mask_img_.shape)), order='C')))[1]\n",
        "    vox_coords = fullfact(img.shape[0:3])[vmask, ::-1]-1\n",
        "    \n",
        "    R = np.array(np.dot(vox_coords, S[0:3, 0:3])) + S[:3, 3]\n",
        "    print(\"Finished: \",nifti_file)\n",
        "    return {'Y': Y, 'R': R}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Q28aQqxwlqM0"
      },
      "source": [
        "#mask = niifiles[0] #set to None if you don't want the images to match\n",
        "mask = None\n",
        "cmu_data = list(map(lambda n: nii2cmu(n, mask),  niifiles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0A719ShaoEz",
        "outputId": "a911edbf-677c-47de-e546-28815059649e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(cmu_data[0]['Y'].T)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  24.15727043   24.12286758   24.1968956  ...   24.21273804\n",
            "    24.21084785   23.78277969]\n",
            " [ 773.53796387  772.43640137  774.80688477 ...  775.31414795\n",
            "   775.25360107  761.54650879]\n",
            " [1346.46289062 1344.3996582  1347.69848633 ... 1349.56494141\n",
            "  1348.94494629 1327.47924805]\n",
            " ...\n",
            " [ 297.91070557  300.08334351  298.43096924 ...  297.62878418\n",
            "   298.12265015  298.896698  ]\n",
            " [ 513.9887085   516.5737915   513.06384277 ...  509.59133911\n",
            "   513.30780029  512.97332764]\n",
            " [ 306.20492554  307.74493408  305.65390015 ...  303.58520508\n",
            "   305.79922485  305.59997559]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81yujS4NlqM0"
      },
      "source": [
        "## Voxel locations\n",
        "\n",
        "We can get explore the nitty-gritties of the data by visualizaing the voxel activations and voxel locations.  For example, let's try plotting the voxel locations (`R`) for the first subject:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ_UH4AXlqM1",
        "outputId": "c9fbc7b3-37c4-44ee-ec53-da7f2468272e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "hyp.plot(cmu_data[0]['R'], 'k.');"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNDW7wK8lqM1"
      },
      "source": [
        "## Voxel activations\n",
        "\n",
        "And now let's plot a sample of voxel activations.  For fun, let's plot the first subject's data as a trajectory using HyperTools.  We'll first project the data down to 3 dimensions using mini batch dictionary learning.  HyperTools supports a wide variety of dimensionality reduction algorithms (more info [here](http://hypertools.readthedocs.io/en/latest/hypertools.plot.html#hypertools.plot)).  Try changing the next cell to reduce the data using Fast ICA (`model='FastICA'`) or creating an animation (`animate=True`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc1hjfahlqM1",
        "outputId": "2c78196e-1a67-48cc-ba9e-b66e7bfe0d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "hyp.plot(cmu_data[2]['Y'], model='IncrementalPCA');"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimYLqJGlqM2"
      },
      "source": [
        "## ☞ Converting between (timepoints by voxels) and (voxels by timepoints) data matrices ##\n",
        "\n",
        "HyperTools and nilearn expect the data matrices to have number-of-timepoints rows and number-of-voxels columns.  BrainIAK expects the data in the transpose of that format-- number-of-voxels by number-of-timepoints matrices.  We can easily convert between the two formats using the `map` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cyEWAGiFlqM2"
      },
      "source": [
        "htfa_data = list(map(lambda x: {'R': x['R'], 'Z': x['Y'].T}, cmu_data))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLOzIxOylqM3"
      },
      "source": [
        "# ☞ Using Topographic Factor Analysis to finding network \"hubs\" in one subject's data #\n",
        "\n",
        "Applying [Topographic Factor Analysis](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094914) (TFA) to a single subject's data reveals a set of `K` spherical network hubs that may be used to characterize the data in a highly compact form that is convenient for summarizing network patterns.  Let's apply TFA to one subject's data and plot the resulting network hubs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMmwB9Q5lqM4",
        "outputId": "b73baf2e-4deb-43ef-a6a5-6222025576d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "nvoxels, ntimepoints = htfa_data[1]['Z'].shape\n",
        "print(nvoxels, ntimepoints)\n",
        "K = 10 #number of hubs to find\n",
        "tfa = TFA(K=K,\n",
        "          max_num_voxel=int(nvoxels*0.05),    #parameterizes the stochastic sampler (number of voxels to consider in each update); increase for precision, decrease for speed\n",
        "          max_num_tr = int(ntimepoints*0.1), #parameterizes the stochastic sampler (number of timepoints to consider in each update)\n",
        "          verbose=False)\n",
        "\n",
        "tfa.fit(htfa_data[1]['Z'], htfa_data[1]['R'])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91388 300\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'include'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exclude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_mimebundle_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"text/plain\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"display\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"diagram\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text/html\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mrepr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0;32m--> 393\u001b[0;31m                                                 self._depth, level)\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         return _safe_repr(\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_changed_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     91\u001b[0m     estimator with non-default values.\"\"\"\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0minit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"deprecated_original\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TFA' object has no attribute 'max_iter'"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-de207696b241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m           verbose=False)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtfa_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtfa_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimebundle_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat_dict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmd_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqbe3_A-lqM4"
      },
      "source": [
        "#plot the hubs on a glass brain!\n",
        "niplot.plot_connectome(np.eye(K), tfa.get_centers(tfa.local_posterior_), node_color='k');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJyIKnXalqM5"
      },
      "source": [
        "## Compare the original vs. TFA-reduced data trajectories\n",
        "\n",
        "We'll use HyperTools to project the original data and the TFA-reduced data onto the same 3D space (using t-SNE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg6hRfJplqM5"
      },
      "source": [
        "reduced_raw = hyp.tools.reduce(htfa_data[0]['Z'], ndims=K)\n",
        "reduced_tfa = tfa.W_.T\n",
        "\n",
        "hyp.plot([reduced_raw, reduced_tfa], align=True, legend=['Original data', 'TFA-reduced data (K = ' + str(K) + ')'], model='TSNE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4xeO883lqM5"
      },
      "source": [
        "# ☞ Visualizing how the brain images are simplified using TFA\n",
        "\n",
        "Above, we defined the `nii2cmu` function to convert nii images to CMU-formatted images.  We can also recover nii images from CMU images.  We'll use this to visualize an example volume from the nifti image we just fit TFA to, and we will also visualize the TFA reconstruction to help us understand which aspects of the data TFA is preserving well (or poorly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "x6qfsev5lqM6"
      },
      "source": [
        "def cmu2nii(Y, R, template):\n",
        "    Y = np.array(Y, ndmin=2)\n",
        "    img = nib.load(template)\n",
        "    S = img.affine\n",
        "    locs = np.array(np.dot(R - S[:3, 3], np.linalg.inv(S[0:3, 0:3])), dtype='int')\n",
        "    \n",
        "    data = np.zeros(tuple(list(img.shape)[0:3]+[Y.shape[0]]))\n",
        "    \n",
        "    # loop over data and locations to fill in activations\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(R.shape[0]):\n",
        "            data[locs[j, 0], locs[j, 1], locs[j, 2], i] = Y[i, j]\n",
        "    \n",
        "    return nib.Nifti1Image(data, affine=img.affine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR8mgoCYlqM7"
      },
      "source": [
        "original_image = cmu2nii(htfa_data[0]['Z'][:, 0].T, htfa_data[0]['R'], niifiles[0])\n",
        "niplot.plot_glass_brain(original_image, plot_abs=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOBLv0v8lqM7"
      },
      "source": [
        "## Reconstructing an image using the fitted TFA posterior\n",
        "\n",
        "TFA decomposes images into the product of a number-of-timepoints by K \"weights\" matrix (`tfa.W_.T`) and a K by number-of-voxels \"factors\" matrix (`tfa.F_.T`).  (Each factor is parameterized by a 3D center and a width parameter, and corresponds to a \"hub\" somewhere in the brain.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCmP7omZlqM7"
      },
      "source": [
        "tfa_reconstruction = cmu2nii(np.dot(np.array(tfa.W_.T[0, :], ndmin=2), tfa.F_.T), htfa_data[0]['R'], niifiles[0])\n",
        "niplot.plot_glass_brain(tfa_reconstruction, plot_abs=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXPzAD2KlqM7"
      },
      "source": [
        "Interestingly, the factors matrix may be constructed on the fly, and we can use any voxel locations to construct it (even if we did not use those locations to fit the original model).  This is sometimes useful, e.g. in that it provides a natural way of converting between images taken at different resolutions or with different sets of voxels.  Let's try doing this same reconstruction, but for a different set of locations (we'll use the standard 2mm voxel MNI brain locations).  Notice that we don't have to re-fit the model...this remapping to any new coordinate space can be done on the fly once we have the fitted TFA model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMN6UVXilqM7"
      },
      "source": [
        "#download the template brain image\n",
        "std_source = 'http://discovery.dartmouth.edu/~jmanning/MIND/avg152T1_brain.nii.gz'\n",
        "std_destination = '/mnt/standard_brain.nii.gz'\n",
        "urllib.request.urlretrieve(std_source, std_destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6PwQlGflqM8"
      },
      "source": [
        "#get the voxel locations\n",
        "std_cmu_img = nii2cmu(std_destination)\n",
        "\n",
        "#re-compute factor matrix at the new locations\n",
        "[unique_R, inds] = tfa.get_unique_R(std_cmu_img['R'])\n",
        "F = tfa.get_factors(unique_R, inds, tfa.get_centers(tfa.local_posterior_), tfa.get_widths(tfa.local_posterior_)).T\n",
        "\n",
        "#plot the inferred activity at the new locations\n",
        "tfa_reconstruction2 = cmu2nii(np.dot(tfa.W_.T[0, :], F), std_cmu_img['R'], std_destination)\n",
        "niplot.plot_glass_brain(tfa_reconstruction2, plot_abs=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYYbn7oKlqM8"
      },
      "source": [
        "### Taking a moment to reflect on what we've just done...\n",
        "\n",
        "It may not look like much, but consider what we've done: we've taken a series of fMRI volumes and inferred a set of \"hubs\" that those volumes reflect.  Then, using just 4 x K numbers to represent the hub locations and radii, and another K numbers to represent the hub weights for the example image (in this case, a total of K x 5 = 50 numbers) we've already captured a lot of the gross low spatial frequency features of the images!  Further, we only need K=10 additional numbers to represent any new image.  Considering that the original images have 94537 voxels (and therefore 94537 activation values *per image*), that's quite a nice compression ratio!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiwbOQJblqM9"
      },
      "source": [
        "# Visualizing one person's \"connectome\" using TFA\n",
        "\n",
        "The weight matrix (`tfa.W_`) tells us how \"active\" each network hub is during each timepoint (image) in the dataset.  We can compute the \"functional connections\" (correlations) between every hub using `sd.pdist`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kij7crrtlqM9"
      },
      "source": [
        "connectome = 1 - sd.squareform(sd.pdist(tfa.W_), 'correlation')\n",
        "niplot.plot_connectome(connectome, \n",
        "                       tfa.get_centers(tfa.local_posterior_), \n",
        "                       node_color='k', \n",
        "                       edge_threshold='75%');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNawnrjXlqM9"
      },
      "source": [
        "# ☞ Visualizing one person's \"dynamic connectome\" using TFA\n",
        "\n",
        "We can compute the connectome during a limited range of times by computing the correlation matrix only for images collected during that limited time window.  To estimate how the connectome changes over time, we can slide a time window over the range of times in our dataset, and compute a connectome for each sliding window.  We'll create a movie by creating a connectome plot for each frame, and then stitching the frames together.\n",
        "\n",
        "To help with this process, we'll create two functions:\n",
        "1. `dynamic_connectome(W, n)`: given a number-of-timepoints by K hub activation matrix (`W`) and a sliding window length (`n`), return a new matrix where each row is the \"[squareform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html#scipy.spatial.distance.squareform)\" of the connectome during that sliding window.\n",
        "2. `animate_connectome(hubs, connectomes)`: given a K by 3 \"hub coordinates\" matrix and the output of `dynamic_connectome`, return an animation object that displays the dynamic connectome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7y_hj7cDlqM9"
      },
      "source": [
        "def dynamic_connectome(W, n):\n",
        "    T = W.shape[0]\n",
        "    K = W.shape[1]\n",
        "    \n",
        "    if n <= 0:\n",
        "        np.array(connectome = 1 - sd.pdist(tfa.W_, 'correlation'), ndmin=2)\n",
        "    else:\n",
        "        connectome = np.zeros([T - n + 1, int((K ** 2 - K) / 2)])\n",
        "        for t in range(T - n + 1):\n",
        "            connectome[t, :] = 1 - sd.pdist(W[t:(t+n), :].T, 'correlation')\n",
        "    return connectome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qWBLE2OqlqM-"
      },
      "source": [
        "def animate_connectome(hubs, connectomes, figstr='figs', force_refresh=False):\n",
        "    \n",
        "    \n",
        "    figdir = os.path.join(destination[0:-(len(data_format)+1)], str(np.unique(K)[0]), figstr)\n",
        "    try:\n",
        "        os.makedirs(figdir)\n",
        "    except:\n",
        "        None\n",
        "    \n",
        "    #save a jpg file for each frame (this takes a while, so don't re-do already made images)\n",
        "    def get_frame(t, fname):\n",
        "        if force_refresh or not os.path.exists(fname):\n",
        "            niplot.plot_connectome(sd.squareform(connectomes[t, :]),\n",
        "                                   hubs,\n",
        "                                   node_color='k',\n",
        "                                   edge_threshold='75%',\n",
        "                                   output_file=fname)\n",
        "    \n",
        "    timepoints = np.arange(connectomes.shape[0])\n",
        "    fnames = list(map(lambda t: os.path.join(figdir, str(t) + '.jpg'), timepoints))\n",
        "    list(map(get_frame, timepoints, fnames))\n",
        "    \n",
        "    #create a movie frame from each of the images we just made\n",
        "    mpl.pyplot.close()\n",
        "    fig = mpl.pyplot.figure()\n",
        "    \n",
        "    def get_im(fname):\n",
        "        #print(fname)\n",
        "        mpl.pyplot.axis('off')\n",
        "        return mpl.pyplot.imshow(mpl.pyplot.imread(fname), animated=True)\n",
        "    \n",
        "    ani = mpl.animation.FuncAnimation(fig, get_im, fnames, interval=50)    \n",
        "    return ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2jLJ_elqM-"
      },
      "source": [
        "### The next cell will take a few minutes to run...\n",
        "\n",
        "The command below creates a connectome image for each movie frame, stiches the images into a movie, and displays it inline as an HTML5 video.  If you run the command a second time, the images won't need to be re-created (they're instead loaded from disk), so the animation will be generated more quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAz0xigflqM_"
      },
      "source": [
        "mpl.rc('animation', html='html5')\n",
        "ani = animate_connectome(tfa.get_centers(tfa.local_posterior_), dynamic_connectome(tfa.W_.T, 20))\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vzLJVb-lqM_"
      },
      "source": [
        "## ⭑ Challenge problems\n",
        "\n",
        "1. Find some other template image (e.g. from another dataset) that's been aligned to MNI space.  Use the fitted model to reconstruct activity patterns from the 10th image in the Pieman dataset, at the locations in that new template image.  Plot the result.\n",
        "2. Re-fit the model using K=5 hubs, and then K=25 hubs.  Reconstruct an example image and plot the results.  Notice how only very low resolution details are preserved when K is small, but higher resolution details start to emerge as K is increased.\n",
        "3. Download a functional .nii or .nii.gz image from somewhere (e.g. from one of the examples above, your own data, etc.) and generate (a) an average \"connectome\" plot using one of the TFA solutions, and (b) a \"dynamic connectome\" animation using one of the TFA solutions (I suggest you use a sliding window of 20-50ish TRs).\n",
        "4. If you create a neat looking animation, save the movie as an MP4 file, [convert it to a GIF](https://mp4togif.online/) and tweet about it (tag with [#MIND17](https://twitter.com/hashtag/MIND17))!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiinssoHlqM_"
      },
      "source": [
        "* * *\n",
        "* * *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9rmk6LElqM_"
      },
      "source": [
        "# ☞ Using Hierarchical Topographic Factor Analysis to finding network \"hubs\" in multi-subject data #\n",
        "\n",
        "[Hierarchical Topographic Factor Analysis](http://www.biorxiv.org/content/early/2017/02/07/106690) (HTFA) extends TFA to work with data from many subjects at the same time.  Applying HTFA to a multi-subject dataset reveals a set of `K` spherical network hubs analogous to the hubs revealed by TFA.  However, HTFA finds a set of hubs that are common across all of the subjects.  Specifically, HTFA finds a common **global template** of K hubs that every subject's data reflects.  In addition, HTFA finds a **subject-specific template** (also called a **local template**) that is particular to each individual subject.  The subject-specific template specifies how each individual is *different* from the global template.\n",
        "\n",
        "Often we want to know something about how people \"in general\" respond to a given experiment, so that's the scenario we'll explore here (via the global template).  However, it is sometimes interesting to also explore individual differences using the local templates.\n",
        "\n",
        "Note: the multi-subject HTFA inference problem is substantially more computationally intensive than the single-subject TFA inference problem.  We'll use some parallelization tricks (using [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface)) to make this run quickly on our small sample dataset, but analyzing a large dataset to do \"real\" analyses requires running the analysis on a multi-core computer cluster.  (If you attempt to analyze a large dataset on a non-cluster computer using the code below, the analysis will likely crash.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeuxuy01lqM_"
      },
      "source": [
        "### The next cell will take a few minutes to run..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nBByqZ1lqNA"
      },
      "source": [
        "#configure MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "if rank == 0:\n",
        "    import logging\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "htfa = HTFA(K=K,\n",
        "            n_subj=len(htfa_data),\n",
        "            max_global_iter=5,\n",
        "            max_local_iter=2,\n",
        "            voxel_ratio=0.5,\n",
        "            tr_ratio=0.5,\n",
        "            max_voxel=int(nvoxels*0.05),\n",
        "            max_tr=int(ntimepoints*0.1),\n",
        "            verbose=False)\n",
        "\n",
        "htfa.fit(list(map(lambda x: x['Z'], htfa_data)), list(map(lambda x: x['R'], htfa_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHpUItdxlqNA"
      },
      "source": [
        "## Plotting HTFA global and local hub locations\n",
        "\n",
        "We'll generate a plot where the global hub locations are shown in black, and each subject's \"local\" hub locations are shown in color (where each subject is assigned a different color).  The hubs should be in similar (but not identical) locations across subjects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfyJdHGnlqNA"
      },
      "source": [
        "#set the node display properties\n",
        "colors = np.repeat(np.vstack([[0, 0, 0], sns.color_palette(\"Spectral\", htfa.n_subj)]), K, axis=0)\n",
        "colors = list(map(lambda x: x[0], np.array_split(colors, colors.shape[0], axis=0))) #make colors into a list\n",
        "sizes = np.repeat(np.hstack([np.array(50), np.array(htfa.n_subj*[20])]), K)\n",
        "\n",
        "#extract the node locations from the fitted htfa model\n",
        "global_centers = htfa.get_centers(htfa.global_posterior_)\n",
        "local_centers = list(map(htfa.get_centers, np.array_split(htfa.local_posterior_, htfa.n_subj)))\n",
        "centers = np.vstack([global_centers, np.vstack(local_centers)])\n",
        "\n",
        "#make the plot\n",
        "niplot.plot_connectome(np.eye(K*(1 + htfa.n_subj)), centers, node_color=colors, node_size=sizes);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilX6qz8blqNB"
      },
      "source": [
        "## HTFA hub activations: multi-subject trajectories\n",
        "\n",
        "Next we'll examine the hub activations from each subject's data (analogous to the \"weights\" we examined from TFA)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUYdzYjlqNB"
      },
      "source": [
        "#The hub weights (for all of the subjects) are stored in a single vector, htfa.local_weights_.\n",
        "#(This is to enable message passing via MPI.)  We need to split up the weights by subject,\n",
        "#and then reshape each subject's hub weights into a K by n_timepoints matrix (which we\n",
        "#take the transpose of, for convenience later on).\n",
        "n_timepoints = list(map(lambda x: x['Z'].shape[1], htfa_data)) #number of timepoints for each person\n",
        "inds = np.hstack([0, np.cumsum(np.multiply(K, n_timepoints))])\n",
        "W = list(map(lambda i: htfa.local_weights_[inds[i]:inds[i+1]].reshape([K, n_timepoints[i]]).T, np.arange(htfa.n_subj)))\n",
        "\n",
        "#now let's use hypertools to plot everyone's trajectories on a single plot...\n",
        "hyp.plot(W);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5PzT5jJlqNB"
      },
      "source": [
        "## ☞ Inter-subject Functional Connectivity (ISFC) with HTFA\n",
        "\n",
        "The \"classic\" way of estimating functional connectivity is to compute the pairwise correlations between voxels or brain regions (or, in our case, \"hubs\").  [Inter-Subject Functional Connectivity](https://docs.wixstatic.com/ugd/b75639_92eab30b43284ca0bd163e3daa709eda.pdf) is designed to home in specifically on *stimulus-driven* correlations.  The ISFC matrix reflects how each voxel's activity (or brain region's activity) is correlated with *the average activity of every other voxel/region, from every other subject*.\n",
        "\n",
        "In other words, whereas classic functional connectivity is concerned with the correlational structure within a single brain, ISFC is concerned with the correlational structure *across* brains.  If two brain regions, *from different people*, exhibit similar activity patterns, then they must be responding to a stimulus that was shared by those brains (and, presumably, the people those brains belong to).  This allows us to identify correlations between brain regions that are specifically driven by shared experiences (e.g. stuff that happens in an experiment).\n",
        "\n",
        "We'll next define a function, `dynamic_ISFC(Ws, n)` for computing static and dynamic ISFC, and then we'll create some plots using the HTFA fits.  Here `Ws` is a list of number-of-timepoints by K matrices, and `n` is the sliding window length.  (We'll write the function so that providing `n <= 0` will return a static ISFC matrix.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3bWG-ikolqNB"
      },
      "source": [
        "def ISFC(data, windowsize=0):\n",
        "    \"\"\"\n",
        "    :param data: a list of number-of-observations by number-of-features matrices\n",
        "    :param windowsize: number of observations to include in each sliding window (set to 0 or don't specify if all\n",
        "                       timepoints should be used)\n",
        "    :return: number-of-features by number-of-features isfc matrix\n",
        "\n",
        "    reference: http://www.nature.com/articles/ncomms12141\n",
        "    \"\"\"\n",
        "\n",
        "    def rows(x): return x.shape[0]\n",
        "    def cols(x): return x.shape[1]\n",
        "    def r2z(r): return 0.5*(np.log(1+r) - np.log(1-r))\n",
        "    def z2r(z): return (np.exp(2*z) - 1)/(np.exp(2*z) + 1)\n",
        "    \n",
        "    def vectorize(m):\n",
        "        np.fill_diagonal(m, 0)\n",
        "        return sd.squareform(m)\n",
        "    \n",
        "    assert len(data) > 1\n",
        "    \n",
        "    ns = list(map(rows, data))\n",
        "    vs = list(map(cols, data))\n",
        "\n",
        "    n = np.min(ns)\n",
        "    if windowsize == 0:\n",
        "        windowsize = n\n",
        "\n",
        "    assert len(np.unique(vs)) == 1\n",
        "    v = vs[0]\n",
        "\n",
        "    isfc_mat = np.zeros([n - windowsize + 1, int((v ** 2 - v)/2)])\n",
        "    for n in range(0, n - windowsize + 1):\n",
        "        next_inds = range(n, n + windowsize)\n",
        "        for i in range(0, len(data)):\n",
        "            mean_other_data = np.zeros([len(next_inds), v])\n",
        "            for j in range(0, len(data)):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                mean_other_data = mean_other_data + data[j][next_inds, :]\n",
        "            mean_other_data /= (len(data)-1)\n",
        "            next_corrs = np.array(r2z(1 - sd.cdist(data[i][next_inds, :].T, mean_other_data.T, 'correlation')))            \n",
        "            isfc_mat[n, :] = isfc_mat[n, :] + vectorize(next_corrs + next_corrs.T)\n",
        "        isfc_mat[n, :] = z2r(isfc_mat[n, :]/(2*len(data)))\n",
        "    \n",
        "    isfc_mat[np.where(np.isnan(isfc_mat))] = 0\n",
        "    return isfc_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21y1JCg5lqNB"
      },
      "source": [
        "### Static ISFC plot\n",
        "\n",
        "On average, how do all of the hubs' activities correlate across people?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqiwVUBrlqNC"
      },
      "source": [
        "static_isfc = ISFC(W)\n",
        "niplot.plot_connectome(sd.squareform(static_isfc[0, :]),\n",
        "                       global_centers,\n",
        "                       node_color='k',\n",
        "                       edge_threshold='75%');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp3zIn3qlqNC"
      },
      "source": [
        "## Dynamic ISFC plot\n",
        "\n",
        "This one will take a little bit of time to run.  We're going to make an animation of ISFC patterns changing over time as people listened to the story."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKcQrS5lqNC"
      },
      "source": [
        "mpl.rc('animation', html='html5')\n",
        "ani = animate_connectome(global_centers, ISFC(W, 20), figstr='isfc')\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8nek-SblqND"
      },
      "source": [
        "## ⭑ Challenge problems\n",
        "\n",
        "1. Try experimenting with different values of K (e.g. try K = 5, K = 20).\n",
        "2. Download another dataset and use the code above to fit HTFA to the dataset.\n",
        "3. Create an ISFC animation with the new fitted model and share the result!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZcoNMVlqND"
      },
      "source": [
        "# Concluding remarks\n",
        "That concludes this tutorial.  Key skills we've covered:\n",
        "- Convert a folder of .nii or .nii.gz files into HyperTools-compatable data matrices (timepoints by voxels numpy arrays) and TFA-compatable data matrices (voxels by timepoints numpy arrays).\n",
        "- Fit TFA to a one person's data and compute (and visualize) dynamic functional connectivity patterns.\n",
        "- Fit HTFA to a multi-person dataset and compute (and visualize) dynamic inter-subject functional connectivity patterns."
      ]
    }
  ]
}